{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:41.104603Z",
     "iopub.status.busy": "2026-01-25T13:27:41.103930Z",
     "iopub.status.idle": "2026-01-25T13:27:41.108138Z",
     "shell.execute_reply": "2026-01-25T13:27:41.107335Z",
     "shell.execute_reply.started": "2026-01-25T13:27:41.104572Z"
    },
    "id": "D7SLJmA3c1yf",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:41.110039Z",
     "iopub.status.busy": "2026-01-25T13:27:41.109534Z",
     "iopub.status.idle": "2026-01-25T13:27:41.437206Z",
     "shell.execute_reply": "2026-01-25T13:27:41.436548Z",
     "shell.execute_reply.started": "2026-01-25T13:27:41.109994Z"
    },
    "id": "0ogw2xEgd3sa",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Quote_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:41.438682Z",
     "iopub.status.busy": "2026-01-25T13:27:41.438427Z",
     "iopub.status.idle": "2026-01-25T13:27:41.462556Z",
     "shell.execute_reply": "2026-01-25T13:27:41.461778Z",
     "shell.execute_reply.started": "2026-01-25T13:27:41.438660Z"
    },
    "id": "AIQDhpZ-eNLR",
    "outputId": "9ebec577-f853-4d77-a7f2-dc8d34940946",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author</th>\n",
       "      <th>Tags</th>\n",
       "      <th>revised_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>â€œBe yourself; everyone else is already taken.â€</td>\n",
       "      <td>Oscar Wilde</td>\n",
       "      <td>attributed-no-source, be-yourself, gilbert-per...</td>\n",
       "      <td>['attributed-no-source', 'be-yourself', 'hones...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>â€œYou've gotta dance like there's nobody watchi...</td>\n",
       "      <td>William W. Purkey</td>\n",
       "      <td>dance, heaven, hurt, inspirational, life, love...</td>\n",
       "      <td>['dance', 'heaven', 'hurt', 'inspirational', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>â€œBe the change that you wish to see in the wor...</td>\n",
       "      <td>Mahatma Gandhi</td>\n",
       "      <td>action, change, inspirational, misattributed-t...</td>\n",
       "      <td>['action', 'change', 'inspirational', 'philoso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>â€œDarkness cannot drive out darkness: only ligh...</td>\n",
       "      <td>Martin Luther King Jr., A Testament of Hope: ...</td>\n",
       "      <td>darkness, drive-out, hate, inspirational, ligh...</td>\n",
       "      <td>['darkness', 'hate', 'inspirational', 'light',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>â€œLive as if you were to die tomorrow. Learn as...</td>\n",
       "      <td>Mahatma Gandhi</td>\n",
       "      <td>carpe-diem, education, inspirational, learning</td>\n",
       "      <td>['carpe-diem', 'education', 'inspirational', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Quote  \\\n",
       "0     â€œBe yourself; everyone else is already taken.â€   \n",
       "1  â€œYou've gotta dance like there's nobody watchi...   \n",
       "2  â€œBe the change that you wish to see in the wor...   \n",
       "3  â€œDarkness cannot drive out darkness: only ligh...   \n",
       "4  â€œLive as if you were to die tomorrow. Learn as...   \n",
       "\n",
       "                                              Author  \\\n",
       "0                                        Oscar Wilde   \n",
       "1                                  William W. Purkey   \n",
       "2                                     Mahatma Gandhi   \n",
       "3   Martin Luther King Jr., A Testament of Hope: ...   \n",
       "4                                     Mahatma Gandhi   \n",
       "\n",
       "                                                Tags  \\\n",
       "0  attributed-no-source, be-yourself, gilbert-per...   \n",
       "1  dance, heaven, hurt, inspirational, life, love...   \n",
       "2  action, change, inspirational, misattributed-t...   \n",
       "3  darkness, drive-out, hate, inspirational, ligh...   \n",
       "4     carpe-diem, education, inspirational, learning   \n",
       "\n",
       "                                        revised_tags  \n",
       "0  ['attributed-no-source', 'be-yourself', 'hones...  \n",
       "1  ['dance', 'heaven', 'hurt', 'inspirational', '...  \n",
       "2  ['action', 'change', 'inspirational', 'philoso...  \n",
       "3  ['darkness', 'hate', 'inspirational', 'light',...  \n",
       "4  ['carpe-diem', 'education', 'inspirational', '...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:41.463692Z",
     "iopub.status.busy": "2026-01-25T13:27:41.463397Z",
     "iopub.status.idle": "2026-01-25T13:27:41.468700Z",
     "shell.execute_reply": "2026-01-25T13:27:41.468113Z",
     "shell.execute_reply.started": "2026-01-25T13:27:41.463664Z"
    },
    "id": "8o0rRkOQeOZn",
    "outputId": "e331cef6-7c91-45e2-8df6-70e66c3e4075",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Quote', 'Author', 'Tags', 'revised_tags'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:41.470858Z",
     "iopub.status.busy": "2026-01-25T13:27:41.470621Z",
     "iopub.status.idle": "2026-01-25T13:27:41.487828Z",
     "shell.execute_reply": "2026-01-25T13:27:41.487058Z",
     "shell.execute_reply.started": "2026-01-25T13:27:41.470837Z"
    },
    "id": "twNX35lqeYIF",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.drop(['Tags', 'revised_tags'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:41.489151Z",
     "iopub.status.busy": "2026-01-25T13:27:41.488842Z",
     "iopub.status.idle": "2026-01-25T13:27:41.505278Z",
     "shell.execute_reply": "2026-01-25T13:27:41.504405Z",
     "shell.execute_reply.started": "2026-01-25T13:27:41.489122Z"
    },
    "id": "qrAmyxDyeePZ",
    "outputId": "1ee82224-1d63-476f-eef2-dbc0f75531f5",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>â€œBe yourself; everyone else is already taken.â€</td>\n",
       "      <td>Oscar Wilde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>â€œYou've gotta dance like there's nobody watchi...</td>\n",
       "      <td>William W. Purkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>â€œBe the change that you wish to see in the wor...</td>\n",
       "      <td>Mahatma Gandhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>â€œDarkness cannot drive out darkness: only ligh...</td>\n",
       "      <td>Martin Luther King Jr., A Testament of Hope: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>â€œLive as if you were to die tomorrow. Learn as...</td>\n",
       "      <td>Mahatma Gandhi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Quote  \\\n",
       "0     â€œBe yourself; everyone else is already taken.â€   \n",
       "1  â€œYou've gotta dance like there's nobody watchi...   \n",
       "2  â€œBe the change that you wish to see in the wor...   \n",
       "3  â€œDarkness cannot drive out darkness: only ligh...   \n",
       "4  â€œLive as if you were to die tomorrow. Learn as...   \n",
       "\n",
       "                                              Author  \n",
       "0                                        Oscar Wilde  \n",
       "1                                  William W. Purkey  \n",
       "2                                     Mahatma Gandhi  \n",
       "3   Martin Luther King Jr., A Testament of Hope: ...  \n",
       "4                                     Mahatma Gandhi  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:41.506582Z",
     "iopub.status.busy": "2026-01-25T13:27:41.506250Z",
     "iopub.status.idle": "2026-01-25T13:27:41.518984Z",
     "shell.execute_reply": "2026-01-25T13:27:41.518227Z",
     "shell.execute_reply.started": "2026-01-25T13:27:41.506548Z"
    },
    "id": "Lw7tVrT5eiPV",
    "outputId": "536cd680-c068-44d0-be4c-521451db859b",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29355, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:41.520300Z",
     "iopub.status.busy": "2026-01-25T13:27:41.519986Z",
     "iopub.status.idle": "2026-01-25T13:27:41.532400Z",
     "shell.execute_reply": "2026-01-25T13:27:41.531842Z",
     "shell.execute_reply.started": "2026-01-25T13:27:41.520271Z"
    },
    "id": "2LHE5vohs0G_",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# df = df[:15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:41.533414Z",
     "iopub.status.busy": "2026-01-25T13:27:41.533163Z",
     "iopub.status.idle": "2026-01-25T13:27:41.550660Z",
     "shell.execute_reply": "2026-01-25T13:27:41.550089Z",
     "shell.execute_reply.started": "2026-01-25T13:27:41.533382Z"
    },
    "id": "Caw0g0mYs5j6",
    "outputId": "c8f43d25-697b-4628-b98d-b32c449b5269",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29355, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:41.551917Z",
     "iopub.status.busy": "2026-01-25T13:27:41.551670Z",
     "iopub.status.idle": "2026-01-25T13:27:41.564665Z",
     "shell.execute_reply": "2026-01-25T13:27:41.564087Z",
     "shell.execute_reply.started": "2026-01-25T13:27:41.551888Z"
    },
    "id": "cCshnDxXekNt",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "quotes = df['Quote'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:41.567178Z",
     "iopub.status.busy": "2026-01-25T13:27:41.566867Z",
     "iopub.status.idle": "2026-01-25T13:27:41.584290Z",
     "shell.execute_reply": "2026-01-25T13:27:41.583572Z",
     "shell.execute_reply.started": "2026-01-25T13:27:41.567145Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Remove null values\n",
    "quotes = quotes.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:41.585660Z",
     "iopub.status.busy": "2026-01-25T13:27:41.585281Z",
     "iopub.status.idle": "2026-01-25T13:27:41.679913Z",
     "shell.execute_reply": "2026-01-25T13:27:41.679263Z",
     "shell.execute_reply.started": "2026-01-25T13:27:41.585629Z"
    },
    "id": "279-IcdfevIA",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "quotes = quotes.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:41.681224Z",
     "iopub.status.busy": "2026-01-25T13:27:41.680876Z",
     "iopub.status.idle": "2026-01-25T13:27:42.571853Z",
     "shell.execute_reply": "2026-01-25T13:27:42.570977Z",
     "shell.execute_reply.started": "2026-01-25T13:27:41.681172Z"
    },
    "id": "OnUcuz06ez2c",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Remove all punctuation marks (.,!?\"' etc.)\n",
    "import string\n",
    "quotes =  quotes.str.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:42.573224Z",
     "iopub.status.busy": "2026-01-25T13:27:42.572916Z",
     "iopub.status.idle": "2026-01-25T13:27:43.034531Z",
     "shell.execute_reply": "2026-01-25T13:27:43.033508Z",
     "shell.execute_reply.started": "2026-01-25T13:27:42.573195Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering: 19,267 quotes\n",
      "Average quote length: 18.1 words\n"
     ]
    }
   ],
   "source": [
    " # Smart filtering: Remove extreme outliers\n",
    "quote_lengths = quotes.str.split().str.len()\n",
    "mean_len = quote_lengths.mean()\n",
    "std_len = quote_lengths.std()\n",
    "\n",
    "# Keep quotes within 2 standard deviations (removes noise)\n",
    "quotes = quotes[(quote_lengths >= 4) & (quote_lengths <= 35)]\n",
    "quotes = quotes.reset_index(drop=True)\n",
    "\n",
    "print(f\"After filtering: {len(quotes):,} quotes\")\n",
    "print(f\"Average quote length: {quotes.str.split().str.len().mean():.1f} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:43.035929Z",
     "iopub.status.busy": "2026-01-25T13:27:43.035691Z",
     "iopub.status.idle": "2026-01-25T13:27:43.041070Z",
     "shell.execute_reply": "2026-01-25T13:27:43.040322Z",
     "shell.execute_reply.started": "2026-01-25T13:27:43.035907Z"
    },
    "id": "Mo1lSnWKe2vW",
    "outputId": "f7a71f9b-27ff-4371-f19b-4e458e98cea6",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         â€œbe yourself everyone else is already takenâ€\n",
       "1    â€œyouve gotta dance like theres nobody watching...\n",
       "2    â€œbe the change that you wish to see in the worldâ€\n",
       "3    â€œdarkness cannot drive out darkness only light...\n",
       "4    â€œlive as if you were to die tomorrow learn as ...\n",
       "Name: Quote, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:43.042356Z",
     "iopub.status.busy": "2026-01-25T13:27:43.042101Z",
     "iopub.status.idle": "2026-01-25T13:27:43.621751Z",
     "shell.execute_reply": "2026-01-25T13:27:43.621173Z",
     "shell.execute_reply.started": "2026-01-25T13:27:43.042335Z"
    },
    "id": "LQhJSPeHfWIF",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "vocab_size = 8000\n",
    "tokenizer = Tokenizer(num_words=vocab_size,oov_token = '<UNK>', filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts(quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:43.622879Z",
     "iopub.status.busy": "2026-01-25T13:27:43.622619Z",
     "iopub.status.idle": "2026-01-25T13:27:43.626577Z",
     "shell.execute_reply": "2026-01-25T13:27:43.625900Z",
     "shell.execute_reply.started": "2026-01-25T13:27:43.622856Z"
    },
    "id": "kmJICvWShDIR",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "# print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:43.627708Z",
     "iopub.status.busy": "2026-01-25T13:27:43.627479Z",
     "iopub.status.idle": "2026-01-25T13:27:43.640317Z",
     "shell.execute_reply": "2026-01-25T13:27:43.639716Z",
     "shell.execute_reply.started": "2026-01-25T13:27:43.627688Z"
    },
    "id": "4Ao60AahrAsx",
    "outputId": "6d4c883e-4e37-430d-cf2d-f42f5f455033",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual vocabulary size: 8001\n"
     ]
    }
   ],
   "source": [
    "actual_vocab_size = vocab_size +1# +1 for padding token at index 0\n",
    "print(f\"Actual vocabulary size: {actual_vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:43.641371Z",
     "iopub.status.busy": "2026-01-25T13:27:43.641135Z",
     "iopub.status.idle": "2026-01-25T13:27:43.655488Z",
     "shell.execute_reply": "2026-01-25T13:27:43.654646Z",
     "shell.execute_reply.started": "2026-01-25T13:27:43.641349Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# actual_vocab_size = min(vocab_size, len(word_index)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:43.656811Z",
     "iopub.status.busy": "2026-01-25T13:27:43.656469Z",
     "iopub.status.idle": "2026-01-25T13:27:43.669969Z",
     "shell.execute_reply": "2026-01-25T13:27:43.669275Z",
     "shell.execute_reply.started": "2026-01-25T13:27:43.656790Z"
    },
    "id": "01QTrJJvheij",
    "outputId": "2f5e380c-37b1-4413-9d03-cdabab517e1c",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26395"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:43.671586Z",
     "iopub.status.busy": "2026-01-25T13:27:43.671045Z",
     "iopub.status.idle": "2026-01-25T13:27:43.689067Z",
     "shell.execute_reply": "2026-01-25T13:27:43.688342Z",
     "shell.execute_reply.started": "2026-01-25T13:27:43.671561Z"
    },
    "id": "orvL8UOYhhEx",
    "outputId": "e0e4c643-d84b-44c0-ac2b-ee684b0790b2",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<UNK>', 1),\n",
       " ('the', 2),\n",
       " ('to', 3),\n",
       " ('is', 4),\n",
       " ('of', 5),\n",
       " ('you', 6),\n",
       " ('a', 7),\n",
       " ('and', 8),\n",
       " ('in', 9),\n",
       " ('that', 10)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(word_index.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:43.690497Z",
     "iopub.status.busy": "2026-01-25T13:27:43.690182Z",
     "iopub.status.idle": "2026-01-25T13:27:44.126465Z",
     "shell.execute_reply": "2026-01-25T13:27:44.125649Z",
     "shell.execute_reply.started": "2026-01-25T13:27:43.690473Z"
    },
    "id": "l9G0FCBThldP",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:44.127548Z",
     "iopub.status.busy": "2026-01-25T13:27:44.127342Z",
     "iopub.status.idle": "2026-01-25T13:27:44.811971Z",
     "shell.execute_reply": "2026-01-25T13:27:44.811198Z",
     "shell.execute_reply.started": "2026-01-25T13:27:44.127529Z"
    },
    "id": "aXfuzdbdj2MG",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Purpose: Create input-output pairs for supervised learning.\n",
    "X = []\n",
    "y = []\n",
    "max_sequence_len = 35  # Limit sequence length to 50 words max\n",
    "\n",
    "for seq in sequences:\n",
    "    # Only use sequences with reasonable length\n",
    "    if len(seq) > 1:\n",
    "        for i in range(1, min(len(seq), max_sequence_len)):\n",
    "            input_seq = seq[:i]\n",
    "            output_seq = seq[i]\n",
    "            X.append(input_seq)\n",
    "            y.append(output_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:44.813194Z",
     "iopub.status.busy": "2026-01-25T13:27:44.812890Z",
     "iopub.status.idle": "2026-01-25T13:27:44.818144Z",
     "shell.execute_reply": "2026-01-25T13:27:44.817517Z",
     "shell.execute_reply.started": "2026-01-25T13:27:44.813154Z"
    },
    "id": "HPQEvlWokDl0",
    "outputId": "6cd321ec-bf45-4693-dc8c-f9ba15daf901",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[361],\n",
       " [361, 120],\n",
       " [361, 120, 253],\n",
       " [361, 120, 253, 227],\n",
       " [361, 120, 253, 227, 4],\n",
       " [361, 120, 253, 227, 4, 416],\n",
       " [2142],\n",
       " [2142, 1923],\n",
       " [2142, 1923, 579],\n",
       " [2142, 1923, 579, 41]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:44.819677Z",
     "iopub.status.busy": "2026-01-25T13:27:44.819038Z",
     "iopub.status.idle": "2026-01-25T13:27:44.832714Z",
     "shell.execute_reply": "2026-01-25T13:27:44.831997Z",
     "shell.execute_reply.started": "2026-01-25T13:27:44.819655Z"
    },
    "id": "Ki-AdmVZkFrB",
    "outputId": "21f6dc19-9ffd-4af3-b697-2bec70756f30",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[120, 253, 227, 4, 416, 6168, 1923, 579, 41, 304]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:44.833929Z",
     "iopub.status.busy": "2026-01-25T13:27:44.833622Z",
     "iopub.status.idle": "2026-01-25T13:27:44.859372Z",
     "shell.execute_reply": "2026-01-25T13:27:44.858663Z",
     "shell.execute_reply.started": "2026-01-25T13:27:44.833908Z"
    },
    "id": "1QSZpb5LkXPH",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "max_len = max(len(x) for x in X) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:44.860478Z",
     "iopub.status.busy": "2026-01-25T13:27:44.860245Z",
     "iopub.status.idle": "2026-01-25T13:27:44.865228Z",
     "shell.execute_reply": "2026-01-25T13:27:44.864559Z",
     "shell.execute_reply.started": "2026-01-25T13:27:44.860447Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:44.866403Z",
     "iopub.status.busy": "2026-01-25T13:27:44.866155Z",
     "iopub.status.idle": "2026-01-25T13:27:45.513164Z",
     "shell.execute_reply": "2026-01-25T13:27:45.512369Z",
     "shell.execute_reply.started": "2026-01-25T13:27:44.866382Z"
    },
    "id": "Gm_7O-s-k0tj",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X_padded = pad_sequences(X, maxlen=max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:45.516882Z",
     "iopub.status.busy": "2026-01-25T13:27:45.516570Z",
     "iopub.status.idle": "2026-01-25T13:27:45.540561Z",
     "shell.execute_reply": "2026-01-25T13:27:45.539771Z",
     "shell.execute_reply.started": "2026-01-25T13:27:45.516859Z"
    },
    "id": "qAg6R70Sk7Y0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:45.542039Z",
     "iopub.status.busy": "2026-01-25T13:27:45.541625Z",
     "iopub.status.idle": "2026-01-25T13:27:45.558320Z",
     "shell.execute_reply": "2026-01-25T13:27:45.557538Z",
     "shell.execute_reply.started": "2026-01-25T13:27:45.541984Z"
    },
    "id": "-v1FaPVnl0m8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:45.559722Z",
     "iopub.status.busy": "2026-01-25T13:27:45.559273Z",
     "iopub.status.idle": "2026-01-25T13:27:45.566599Z",
     "shell.execute_reply": "2026-01-25T13:27:45.565933Z",
     "shell.execute_reply.started": "2026-01-25T13:27:45.559691Z"
    },
    "id": "wFhn2lPHmIJF",
    "outputId": "da6aeb00-9379-45e5-e520-68abe0e9414a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "embedding_dim = 200\n",
    "lstm_units = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:45.567920Z",
     "iopub.status.busy": "2026-01-25T13:27:45.567713Z",
     "iopub.status.idle": "2026-01-25T13:27:46.319789Z",
     "shell.execute_reply": "2026-01-25T13:27:46.318935Z",
     "shell.execute_reply.started": "2026-01-25T13:27:45.567899Z"
    },
    "id": "zhc42h1enQQP",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1769347666.271606      55 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GRU\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(actual_vocab_size, 128, mask_zero=True),\n",
    "    GRU(256, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dropout(0.3),\n",
    "    Dense(actual_vocab_size, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:46.321112Z",
     "iopub.status.busy": "2026-01-25T13:27:46.320805Z",
     "iopub.status.idle": "2026-01-25T13:27:46.357371Z",
     "shell.execute_reply": "2026-01-25T13:27:46.356711Z",
     "shell.execute_reply.started": "2026-01-25T13:27:46.321081Z"
    },
    "id": "g6QXk-KBnZZz",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ gru (\u001b[38;5;33mGRU\u001b[0m)                       â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.metrics import SparseTopKCategoricalAccuracy\n",
    "\n",
    "# Optimizer with custom learning rate\n",
    "optimizer = Adam(learning_rate=0.001, clipnorm=1.0)  # Gradient clipping prevents explosion\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',\n",
    "            SparseTopKCategoricalAccuracy(k=3, name='top_3_acc'),\n",
    "            SparseTopKCategoricalAccuracy(k=5, name='top_5_acc')\n",
    "            ]\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "execution": {
     "iopub.execute_input": "2026-01-25T13:27:46.358473Z",
     "iopub.status.busy": "2026-01-25T13:27:46.358183Z",
     "iopub.status.idle": "2026-01-25T13:27:46.362763Z",
     "shell.execute_reply": "2026-01-25T13:27:46.362040Z",
     "shell.execute_reply.started": "2026-01-25T13:27:46.358445Z"
    },
    "id": "Fwf7OByInlD7",
    "outputId": "a506ac6d-d6bb-423d-b0e0-a199d9652792",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save best model during training\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_quote_model.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Early stopping - but with more patience\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,  # More patience for complex model\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Reduce learning rate when stuck\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=0.00001,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QE7CSaInnpJ6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Train for more epochs - P100 can handle it\n",
    "start_time = time.time()\n",
    "history = model.fit(\n",
    "    X_padded, y,\n",
    "    validation_split=0.2,  # 20% validation\n",
    "    epochs=100,  # Will stop early if converging\n",
    "    batch_size=128,  # Optimal for P100\n",
    "    callbacks=[checkpoint, early_stopping,reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "training_time = (time.time() - start_time) / 60\n",
    "print(f\"\\nTraining completed in {training_time:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "final_train_acc = history.history['accuracy'][-1]\n",
    "final_val_acc = history.history['val_accuracy'][-1]\n",
    "final_train_loss = history.history['loss'][-1]\n",
    "final_val_loss = history.history['val_loss'][-1]\n",
    "best_val_acc = max(history.history['val_accuracy'])\n",
    "best_epoch = history.history['val_accuracy'].index(best_val_acc) + 1\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“ˆ TRAINING RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total Epochs:           {len(history.history['loss'])}\")\n",
    "print(f\"Best Epoch:             {best_epoch}\")\n",
    "# print(f\"Training Time:          {training_time:.1f} minutes\")\n",
    "print(f\"\\nFinal Training Accuracy:    {final_train_acc:.2%}\")\n",
    "print(f\"Final Validation Accuracy:  {final_val_acc:.2%}\")\n",
    "print(f\"Best Validation Accuracy:   {best_val_acc:.2%}\")\n",
    "print(f\"\\nFinal Training Loss:        {final_train_loss:.4f}\")\n",
    "print(f\"Final Validation Loss:      {final_val_loss:.4f}\")\n",
    "print(f\"\\nOverfitting Gap:            {(final_train_acc - final_val_acc):.2%}\")\n",
    "\n",
    "if final_train_acc - final_val_acc < 0.10:\n",
    "    print(\"âœ… EXCELLENT! Very low overfitting\")\n",
    "elif final_train_acc - final_val_acc < 0.20:\n",
    "    print(\"âœ… GOOD! Acceptable overfitting\")\n",
    "elif final_train_acc - final_val_acc < 0.30:\n",
    "    print(\"âš ï¸ MODERATE overfitting\")\n",
    "else:\n",
    "    print(\"âŒ HIGH overfitting - consider more regularization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('quote_generator_model_3.keras')\n",
    "\n",
    "# Save the tokenizer\n",
    "import pickle\n",
    "\n",
    "with open('tokenizer_3.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "# Save important parameters\n",
    "import json\n",
    "model_params = {\n",
    "    'max_len': int(max_len),\n",
    "    'actual_vocab_size': int(actual_vocab_size),\n",
    "    'embedding_dim': embedding_dim,\n",
    "    'lstm_units': lstm_units,\n",
    "    'training_samples': len(X),\n",
    "    # 'training_time_minutes': float(training_time),\n",
    "    'final_train_accuracy': float(final_train_acc),\n",
    "    'final_val_accuracy': float(final_val_acc),\n",
    "    'best_val_accuracy': float(best_val_acc),\n",
    "    'final_train_loss': float(final_train_loss),\n",
    "    'final_val_loss': float(final_val_loss),\n",
    "    'epochs_trained': len(history.history['loss']),\n",
    "    'best_epoch': int(best_epoch)\n",
    "}\n",
    "\n",
    "with open('model_params_3.json', 'w') as f:\n",
    "    json.dump(model_params, f, indent=2)\n",
    "\n",
    "# Save training history\n",
    "history_dict = {\n",
    "    'accuracy': [float(x) for x in history.history['accuracy']],\n",
    "    'val_accuracy': [float(x) for x in history.history['val_accuracy']],\n",
    "    'loss': [float(x) for x in history.history['loss']],\n",
    "    'val_loss': [float(x) for x in history.history['val_loss']]\n",
    "}\n",
    "\n",
    "with open('training_history_3.json', 'w') as f:\n",
    "    json.dump(history_dict, f, indent=2)\n",
    "\n",
    "print(\"âœ… quote_generator_model_3.keras\")\n",
    "print(\"âœ… best_quote_generator_model_3.keras (saved during training)\")\n",
    "print(\"âœ… tokenizer_3.pkl\")\n",
    "print(\"âœ… model_params_3.json\")\n",
    "print(\"âœ… training_history.json\")\n",
    "\n",
    "\n",
    "print(\"âœ… Model saved successfully!\")\n",
    "print(\"âœ… Tokenizer saved successfully!\")\n",
    "print(\"âœ… Parameters saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load the model\n",
    "# model = load_model('model/quote_generator_model_3.keras')\n",
    "model  = load_model('model/best_quote_model.keras')\n",
    "\n",
    "# Load the tokenizer\n",
    "with open('model/tokenizer_3.pkl', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "# Load parameters\n",
    "with open('json/model_params_3.json', 'r') as f:\n",
    "    model_params = json.load(f)\n",
    "\n",
    "max_len = model_params['max_len']\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print(\"âœ… Everything loaded successfully!\")\n",
    "print(f\"ğŸ“Š Vocabulary size: {model_params['actual_vocab_size']}\")\n",
    "print(f\"ğŸ“ Max sequence length: {max_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create reverse index ONCE (outside function for speed)\n",
    "reverse_word_index = {v: k for k, v in tokenizer.word_index.items()}\n",
    "\n",
    "def generate_quote(seed_text, next_words=10, temperature=0.8, top_k=50):\n",
    "    \"\"\"\n",
    "    Generate text with improved quality\n",
    "    \n",
    "    Args:\n",
    "        seed_text: Starting text\n",
    "        next_words: Number of words to generate\n",
    "        temperature: Randomness (0.5=safe, 1.0=balanced, 1.5=creative)\n",
    "        top_k: Only sample from top k predictions (prevents bad words)\n",
    "    \"\"\"\n",
    "    result = seed_text.lower()\n",
    "    \n",
    "    for _ in range(next_words):\n",
    "        # Tokenize current text\n",
    "        token_list = tokenizer.texts_to_sequences([result])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_len, padding='pre')\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = model.predict(token_list, verbose=0)[0]\n",
    "        \n",
    "        # ============================================\n",
    "        # FILTER BAD TOKENS\n",
    "        # ============================================\n",
    "        # Remove <PAD> and <UNK>\n",
    "        predictions[0] = 0  # <PAD>\n",
    "        predictions[1] = 0  # <UNK>\n",
    "        \n",
    "        # Renormalize\n",
    "        if predictions.sum() == 0:\n",
    "            break\n",
    "        predictions = predictions / predictions.sum()\n",
    "        \n",
    "        # ============================================\n",
    "        # TOP-K SAMPLING (Better quality)\n",
    "        # ============================================\n",
    "        # Get top k predictions\n",
    "        top_k_indices = np.argsort(predictions)[-top_k:]\n",
    "        top_k_probs = predictions[top_k_indices]\n",
    "        \n",
    "        # Apply temperature to top-k only\n",
    "        top_k_probs = np.power(top_k_probs, 1/temperature)\n",
    "        top_k_probs = top_k_probs / top_k_probs.sum()\n",
    "        \n",
    "        # Sample from top-k\n",
    "        predicted_id = np.random.choice(top_k_indices, p=top_k_probs)\n",
    "        \n",
    "        # ============================================\n",
    "        # GET WORD\n",
    "        # ============================================\n",
    "        output_word = reverse_word_index.get(predicted_id, \"\")\n",
    "        \n",
    "        # Safety check\n",
    "        if not output_word or output_word in [\"<UNK>\", \"<PAD>\"]:\n",
    "            break\n",
    "            \n",
    "        result += \" \" + output_word\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Test with different temperatures\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ¨ GENERATED QUOTES (Multiple Temperatures)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "seeds = [\"life is\", \"love is\", \"be yourself\", \"the only\", \"success comes\"]\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Seed: '{seed}'\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Conservative (more predictable)\n",
    "    quote1 = generate_quote(seed, next_words=10, temperature=0.5, top_k=30)\n",
    "    print(f\"ğŸ”µ Safe (T=0.5):     {quote1}\")\n",
    "    \n",
    "    # Balanced\n",
    "    quote2 = generate_quote(seed, next_words=10, temperature=0.8, top_k=50)\n",
    "    print(f\"ğŸŸ¢ Balanced (T=0.8): {quote2}\")\n",
    "    \n",
    "    # Creative (more random)\n",
    "    quote3 = generate_quote(seed, next_words=10, temperature=1.2, top_k=100)\n",
    "    print(f\"ğŸŸ¡ Creative (T=1.2): {quote3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "runtime_attributes": {
    "runtime_version": "2025.10"
   }
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 9329250,
     "sourceId": 14605373,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31261,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "dsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
